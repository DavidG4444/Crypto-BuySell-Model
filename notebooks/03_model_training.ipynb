{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7ab390",
   "metadata": {},
   "source": [
    "## Step 5 --- Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56060cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 28 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   open_time           1000 non-null   object \n",
      " 1   open                1000 non-null   float64\n",
      " 2   high                1000 non-null   float64\n",
      " 3   low                 1000 non-null   float64\n",
      " 4   close               1000 non-null   float64\n",
      " 5   volume              1000 non-null   float64\n",
      " 6   close_time          1000 non-null   object \n",
      " 7   quote_asset_volume  1000 non-null   float64\n",
      " 8   num_trades          1000 non-null   float64\n",
      " 9   taker_base_volume   1000 non-null   float64\n",
      " 10  taker_quote_volume  1000 non-null   float64\n",
      " 11  return_1d           999 non-null    float64\n",
      " 12  return_7d           993 non-null    float64\n",
      " 13  rolling_volatility  993 non-null    float64\n",
      " 14  rsi                 987 non-null    float64\n",
      " 15  sma_20              981 non-null    float64\n",
      " 16  sma_50              951 non-null    float64\n",
      " 17  sma_200             801 non-null    float64\n",
      " 18  bb_upper            981 non-null    float64\n",
      " 19  bb_middle           981 non-null    float64\n",
      " 20  bb_lower            981 non-null    float64\n",
      " 21  macd                975 non-null    float64\n",
      " 22  macd_signal         967 non-null    float64\n",
      " 23  macd_histogram      967 non-null    float64\n",
      " 24  stoch_k             987 non-null    float64\n",
      " 25  stoch_d             985 non-null    float64\n",
      " 26  future_return       999 non-null    float64\n",
      " 27  label               1000 non-null   int64  \n",
      "dtypes: float64(25), int64(1), object(2)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(r\"C:\\Users\\USER\\OneDrive\\Desktop\\LuxDev DSA\\Capstone-Project\\Crypto-BuySell-Model\\data\\processed\\BTCUSDT_1dmodified.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c09e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "  Train: 170 samples - Index 0 to 169\n",
      "  Test: 166 samples - Index 170 to 335\n",
      "\n",
      "Split 2:\n",
      "  Train: 336 samples - Index 0 to 335\n",
      "  Test: 166 samples - Index 336 to 501\n",
      "\n",
      "Split 3:\n",
      "  Train: 502 samples - Index 0 to 501\n",
      "  Test: 166 samples - Index 502 to 667\n",
      "\n",
      "Split 4:\n",
      "  Train: 668 samples - Index 0 to 667\n",
      "  Test: 166 samples - Index 668 to 833\n",
      "\n",
      "Split 5:\n",
      "  Train: 834 samples - Index 0 to 833\n",
      "  Test: 166 samples - Index 834 to 999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Visualize the splits\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(df)):\n",
    "    print(f\"Split {i+1}:\")\n",
    "    print(f\"  Train: {len(train_index)} samples - Index {train_index[0]} to {train_index[-1]}\")\n",
    "    print(f\"  Test: {len(test_index)} samples - Index {test_index[0]} to {test_index[-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcae30b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m test = df.iloc[val_size:]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Or with features and target\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m X_train = df[\u001b[43mfeature_cols\u001b[49m].iloc[:train_size]\n\u001b[32m     12\u001b[39m X_val = df[feature_cols].iloc[train_size:val_size]\n\u001b[32m     13\u001b[39m X_test = df[feature_cols].iloc[val_size:]\n",
      "\u001b[31mNameError\u001b[39m: name 'feature_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "train_size = int(len(df) * 0.70)\n",
    "val_size = int(len(df) * 0.85)\n",
    "\n",
    "# Split the data\n",
    "train = df.iloc[:train_size]\n",
    "val = df.iloc[train_size:val_size]\n",
    "test = df.iloc[val_size:]\n",
    "\n",
    "# Or with features and target\n",
    "X_train = df[feature_cols].iloc[:train_size]\n",
    "X_val = df[feature_cols].iloc[train_size:val_size]\n",
    "X_test = df[feature_cols].iloc[val_size:]\n",
    "\n",
    "y_train = df[target_col].iloc[:train_size]\n",
    "y_val = df[target_col].iloc[train_size:val_size]\n",
    "y_test = df[target_col].iloc[val_size:]\n",
    "\n",
    "print(f\"Train: {len(train)} samples ({len(train)/len(df)*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val)} samples ({len(val)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test: {len(test)} samples ({len(test)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e68d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca286ee5",
   "metadata": {},
   "source": [
    "## Step 6 --- Model Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
